{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_codes():\n",
    "    \"\"\"Returns a list of all current NBA team codes\"\"\"\n",
    "    return [\n",
    "        'ATL', 'BOS', 'BRK', 'CHI', 'CHO', 'CLE', 'DAL', 'DEN', 'DET', 'GSW',\n",
    "        'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NOP', 'NYK',\n",
    "        'OKC', 'ORL', 'PHI', 'PHO', 'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_stats_categories():\n",
    "    '''Retunrs a list of all the statistics in the advanced game log on\n",
    "    Basketball Reference that are numberic (eg PtsFwd as opposed to Opponent)'''\n",
    "    return [\n",
    "        'PtsFwd', 'PtsAgt', 'ORtg','DRtg', 'Pace', 'FTr', '3PAr',\n",
    "        'TS%','TRB%', 'AST%', 'STL%', 'BLK%', 'eFG%', 'TOV%',\n",
    "        'ORB%', 'FT/FGA', 'OppeFG%', 'OppTOV%', 'DRB%', 'OppFT/FGA'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_team_advanced_gamelog(team_code, year):\n",
    "    \"\"\"\n",
    "    Scrapes advanced game log for a specific team and year.\n",
    "    \n",
    "    Args:\n",
    "        team_code (str): Team code (e.g., 'CHO' for Charlotte).\n",
    "        year (int): Season year (e.g., 2024 for the 2023-24 season).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned advanced game log data, or None if scraping fails.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.basketball-reference.com/teams/{team_code}/{year}/gamelog-advanced/\"\n",
    "    \n",
    "    # Add a polite delay to avoid overloading the server\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        # Fetch the page\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Check if the page contains valid data\n",
    "        if \"Page Not Found\" in response.text:\n",
    "            print(f\"Warning: No data found for {team_code} {year}\")\n",
    "            return None\n",
    "        \n",
    "        # Parse the HTML and extract the advanced game log table\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', id='tgl_advanced')\n",
    "        \n",
    "        if table is None:\n",
    "            print(f\"Warning: No table found for {team_code} {year}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert the HTML table to a DataFrame\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred for {team_code}: {http_err}\")\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Connection error occurred for {team_code}: {conn_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred for {team_code}: {err}\")\n",
    "    \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_df(team_code:str, year=2025):\n",
    "    # Scrape regular season stats\n",
    "    df = scrape_team_advanced_gamelog(team_code, year)\n",
    "\n",
    "    # Set column names to the stats they represent\n",
    "    df.columns = df.columns.get_level_values(1)\n",
    "\n",
    "    # Make Game Number (G) the index\n",
    "    df.set_index('G', inplace=True)\n",
    "\n",
    "    # Drop unneccessary columns\n",
    "    df.drop(columns=['Rk'], inplace=True)\n",
    "    df.drop(columns=['Unnamed: 18_level_1'], inplace=True)\n",
    "    df.drop(columns=['Unnamed: 23_level_1'], inplace=True)\n",
    "\n",
    "\n",
    "    # Rename columns\n",
    "    df.rename(columns={'Unnamed: 3_level_1': 'Home/Away'}, inplace=True)\n",
    "    df.rename(columns={'Tm': 'PtsFwd'}, inplace=True)\n",
    "    df.rename(columns={'Opp': 'PtsAgt'}, inplace=True)\n",
    "    df.columns.values[2] = 'Opponent'        # Column indexed at 2 and 5 both titled 'Opp' originally\n",
    "    df.columns.values[20] = 'OppeFG%'\n",
    "    df.columns.values[21] = 'OppTOV%'\n",
    "    df.columns.values[23] = 'OppFT/FGA'\n",
    "\n",
    "    # Need to drop Opponent here because renaming it above, also Date because of how I set things up\n",
    "    df.drop(columns=['Date', 'Opponent'], inplace=True)\n",
    "\n",
    "    # Drop extraneous rows that do not house game info\n",
    "    df = df[df.index.notnull()]  # Keep only non-NaN indices (ie rows without the 3 collective headers)\n",
    "    df = df[df.index != \"G\"]     # Keep only rows wiht games (ie rows without individual stat headers)\n",
    "\n",
    "    # Edit values in Home/Away column to be 1 and 0\n",
    "    df['Home/Away'] = df['Home/Away'].fillna('1')\n",
    "    df['Home/Away'] = df['Home/Away'].replace('@', '0')\n",
    "\n",
    "    # Edit values in W/L to be 1/0\n",
    "    df['W/L'] = df['W/L'].replace('W', '1')\n",
    "    df['W/L'] = df['W/L'].replace('L', '0')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_avgs(raw_data_df):\n",
    "    # Take the stats and make them rolling averages (currently past 5 games but may be interesting to optimize)\n",
    "    number_stats = get_number_stats_categories()\n",
    "    rolling_avgs = raw_data_df.copy()\n",
    "\n",
    "    # For every stat that is a number, get the rolling average and drop the non-rolling avg column of that same stat\n",
    "    for stat in number_stats:\n",
    "        rolling_avgs[f'Avg_{stat}'] = rolling_avgs[stat].shift().rolling(5).mean()\n",
    "        rolling_avgs = rolling_avgs.drop(columns=stat)\n",
    "\n",
    "    # Drop the first five rows becasue they are all NaN\n",
    "    rolling_avgs = rolling_avgs.drop(index=rolling_avgs.index[:5])\n",
    "\n",
    "    return rolling_avgs\n",
    "\n",
    "def get_next_row(raw_data_df, home_away):\n",
    "    number_stats = get_number_stats_categories()\n",
    "    \n",
    "    # Get last 5 games and make an explicit copy\n",
    "    last_5_games = raw_data_df.tail(5).copy()\n",
    "    \n",
    "    # Convert to numeric\n",
    "    for stat in number_stats:\n",
    "        last_5_games[stat] = pd.to_numeric(last_5_games[stat], errors='coerce')\n",
    "    \n",
    "    # Calculate averages for next game\n",
    "    next_game_features = {}\n",
    "    for stat in number_stats:\n",
    "        next_game_features[f'Avg_{stat}'] = last_5_games[stat].mean()\n",
    "    \n",
    "    # Create single row DataFrame with home/away\n",
    "    next_game_row = pd.DataFrame([next_game_features])\n",
    "    next_game_row.insert(0, 'Home/Away', home_away)\n",
    "    \n",
    "    return next_game_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standrdized_stats(rolling_avgs_df):\n",
    "    numeric_features = rolling_avgs_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    rolling_avgs_df[numeric_features] = scaler.fit_transform(rolling_avgs_df[numeric_features])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(rolling_avgs, next_game_row):\n",
    "\n",
    "    X = rolling_avgs.drop(columns=['W/L'])\n",
    "    y = rolling_avgs['W/L']\n",
    "\n",
    "    # Use 20% of the data for testing, 80% for training\n",
    "    test_size = int(X.shape[0] * 0.2)\n",
    "\n",
    "    # Split data into train and test\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "\n",
    "    # Train the logistic regression model\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "    # Predict the next game\n",
    "    predicted_outcome = model.predict(next_game_row)\n",
    "    predicted_probability = model.predict_proba(next_game_row)\n",
    "    print(\"Predicted Outcome (1=Win, 0=Loss):\", predicted_outcome[0])\n",
    "    print(\"Win Probability:\", predicted_probability[0][1])  # Probability for label 1\n",
    "    print(\"Loss Probability:\", predicted_probability[0][0])  # Probability for label 0\n",
    "    print()\n",
    "    print('y_test', y_test)\n",
    "    print('y_pred', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚨🏀 ***Predicting the Future of NBA Games!*** 🏀🚨\n",
    "\n",
    "Prepare to witness **data-driven dominance** as we bring cutting-edge machine learning to the court! My technical prowess makes even the most decorated champions pale in comparison to this analytics masterpiece. 🧠📈\n",
    "\n",
    "With rolling averages, advanced metrics, and a model trained to perfection, we're not just predicting games—we're redefining the game. 🚀✨\n",
    "\n",
    "This isn’t guesswork. This is **next-level basketball analytics** that leaves luck on the bench.\n",
    "\n",
    "Ready to see what the future holds? Let’s get that **W**! 🏆🔥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulls = get_raw_df('CHI')\n",
    "#bulls.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulls_next_game = get_next_row(bulls, 1)\n",
    "#bulls_next_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.20      0.50      0.29         5\n",
      "weighted avg       0.16      0.40      0.23         5\n",
      "\n",
      "\n",
      "Predicted Outcome (1=Win, 0=Loss): 1\n",
      "Win Probability: 1.0\n",
      "Loss Probability: 0.0\n",
      "\n",
      "y_test G\n",
      "27    1\n",
      "28    1\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "Name: W/L, dtype: object\n",
      "y_pred ['1' '1' '1' '1' '1']\n",
      "\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.30      0.50      0.38         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n",
      "\n",
      "Predicted Outcome (1=Win, 0=Loss): 0\n",
      "Win Probability: 9.322891091749652e-40\n",
      "Loss Probability: 1.0\n",
      "\n",
      "y_test G\n",
      "26    1\n",
      "27    0\n",
      "28    1\n",
      "29    0\n",
      "30    0\n",
      "Name: W/L, dtype: object\n",
      "y_pred ['0' '0' '0' '0' '0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Scrape the advanced stats for two NBA teams that are going to play each other next (eg. CHI and BOS)\n",
    "bulls = get_raw_df('CHI')\n",
    "celtics = get_raw_df('BOS')\n",
    "\n",
    "# Get the rolling averages and next game stats for each team and 1 if they're home, 0 if away\n",
    "bulls_rolling_avg = get_rolling_avgs(bulls)\n",
    "bulls_next_game = get_next_row(bulls, 1)\n",
    "\n",
    "celtics_rolling_avg = get_rolling_avgs(celtics)\n",
    "celtics_next_game = get_next_row(celtics, 0)\n",
    "\n",
    "# Standardize the features\n",
    "get_standrdized_stats(bulls_rolling_avg)\n",
    "get_standrdized_stats(celtics_rolling_avg)\n",
    "\n",
    "# Run the logistic regression\n",
    "logistic_regression(bulls_rolling_avg, bulls_next_game)\n",
    "print()\n",
    "logistic_regression(celtics_rolling_avg, celtics_next_game)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate the stuff I've done with the stuff CHAT's done/I haven't explored**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the separation more apparent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Avg_PtsFwd', 'Avg_DRtg', 'Avg_3PAr', 'Avg_AST%', 'Avg_STL%',\n",
      "       'Avg_BLK%', 'Avg_FT/FGA', 'Avg_OppeFG%', 'Avg_OppTOV%',\n",
      "       'Avg_OppFT/FGA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Perform RFE\n",
    "rfe = RFE(model, n_features_to_select=10)  # Adjust the number of features to keep\n",
    "#rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def calibrated_logistic_regression(rolling_avgs, next_game_row):\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    # Prepare data\n",
    "    X = rolling_avgs.drop(columns=['W/L'])\n",
    "    y = rolling_avgs['W/L']\n",
    "    \n",
    "    # Get feature columns to ensure consistency\n",
    "    feature_columns = X.columns\n",
    "    next_game_row = next_game_row[feature_columns]  # Ensure same columns as training data\n",
    "    \n",
    "    # Split data \n",
    "    test_size = int(X.shape[0] * 0.2)\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "    \n",
    "    # Create pipeline with imputer\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', C=1.0, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Calibrated model\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        pipeline, \n",
    "        cv=2,\n",
    "        method='sigmoid'\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = calibrated_model.predict(X_test)\n",
    "    y_pred_proba = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    \n",
    "    # Predict next game\n",
    "    predicted_outcome = calibrated_model.predict(next_game_row)\n",
    "    predicted_proba = calibrated_model.predict_proba(next_game_row)\n",
    "    \n",
    "    print(\"Predicted Outcome (1=Win, 0=Loss):\", predicted_outcome[0])\n",
    "    print(\"Win Probability: {:.2%}\".format(predicted_proba[0][1]))\n",
    "    print(\"Loss Probability: {:.2%}\".format(predicted_proba[0][0]))\n",
    "    \n",
    "    return calibrated_model, y_test, y_pred\n",
    "\n",
    "def get_next_row(raw_data_df, home_away):\n",
    "    # Get and validate stats\n",
    "    number_stats = get_number_stats_categories()\n",
    "    number_stats = [stat for stat in number_stats if stat in raw_data_df.columns]\n",
    "    \n",
    "    # Get last 5 games and ensure numeric\n",
    "    last_5_games = raw_data_df.tail(5).copy()\n",
    "    for stat in number_stats:\n",
    "        last_5_games[stat] = pd.to_numeric(last_5_games[stat], errors='coerce')\n",
    "    \n",
    "    # Calculate averages for next game\n",
    "    next_game_features = {}\n",
    "    for stat in number_stats:\n",
    "        next_game_features[f'Avg_{stat}'] = last_5_games[stat].mean()\n",
    "    \n",
    "    # Add derived features\n",
    "    next_game_features['Off_Eff'] = next_game_features['Avg_ORtg'] * next_game_features['Avg_eFG%']\n",
    "    next_game_features['Def_Eff'] = next_game_features['Avg_DRtg'] * next_game_features['Avg_OppeFG%']\n",
    "    next_game_features['Off_Def_Ratio'] = next_game_features['Avg_ORtg'] / next_game_features['Avg_DRtg']\n",
    "    \n",
    "    # Calculate Win_Streak from last 5 games\n",
    "    next_game_features['Win_Streak'] = (last_5_games['W/L'] == '1').sum()\n",
    "    \n",
    "    # Create single row DataFrame with home/away\n",
    "    next_game_row = pd.DataFrame([next_game_features])\n",
    "    next_game_row.insert(0, 'Home/Away', home_away)\n",
    "    \n",
    "    # Standardize features to match training data\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = next_game_row.select_dtypes(include=['float64']).columns\n",
    "    next_game_row[numeric_features] = scaler.fit_transform(next_game_row[numeric_features])\n",
    "    \n",
    "    return next_game_row\n",
    "\n",
    "def cross_validate_model(X, y, n_splits=2):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    # Create pipeline with imputer\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        y_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        aucs.append(auc)\n",
    "        \n",
    "        print(f\"Fold {fold} - Accuracy: {acc:.3f}, AUC: {auc:.3f}\")\n",
    "    \n",
    "    print(f\"\\nAverage Accuracy: {np.mean(accuracies):.3f} (+/- {np.std(accuracies):.3f})\")\n",
    "    print(f\"Average AUC: {np.mean(aucs):.3f} (+/- {np.std(aucs):.3f})\")\n",
    "\n",
    "\n",
    "def enhance_features(rolling_avgs_df):\n",
    "    # Create interaction features\n",
    "    rolling_avgs_df['Off_Eff'] = rolling_avgs_df['Avg_ORtg'] * rolling_avgs_df['Avg_eFG%']\n",
    "    rolling_avgs_df['Def_Eff'] = rolling_avgs_df['Avg_DRtg'] * rolling_avgs_df['Avg_OppeFG%']\n",
    "    \n",
    "    # Create momentum features (if you have date information)\n",
    "    rolling_avgs_df['Win_Streak'] = (rolling_avgs_df['W/L'] == '1').rolling(5).sum()\n",
    "    \n",
    "    # Create relative metrics\n",
    "    rolling_avgs_df['Off_Def_Ratio'] = rolling_avgs_df['Avg_ORtg'] / rolling_avgs_df['Avg_DRtg']\n",
    "    \n",
    "    # Standardize all numeric features\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = rolling_avgs_df.select_dtypes(include=['float64']).columns\n",
    "    rolling_avgs_df[numeric_features] = scaler.fit_transform(rolling_avgs_df[numeric_features])\n",
    "    \n",
    "    return rolling_avgs_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 0.500, AUC: 0.667\n",
      "Fold 2 - Accuracy: 0.571, AUC: 0.600\n",
      "\n",
      "Average Accuracy: 0.536 (+/- 0.036)\n",
      "Average AUC: 0.633 (+/- 0.033)\n",
      "Accuracy: 0.3333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n",
      "\n",
      "Predicted Outcome (1=Win, 0=Loss): 0\n",
      "Win Probability: 32.60%\n",
      "Loss Probability: 67.40%\n",
      "Fold 1 - Accuracy: 0.571, AUC: 0.667\n",
      "Fold 2 - Accuracy: 0.833, AUC: 1.000\n",
      "\n",
      "Average Accuracy: 0.702 (+/- 0.131)\n",
      "Average AUC: 0.833 (+/- 0.167)\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "\n",
      "Predicted Outcome (1=Win, 0=Loss): 1\n",
      "Win Probability: 74.80%\n",
      "Loss Probability: 25.20%\n"
     ]
    }
   ],
   "source": [
    "bulls = get_raw_df('CHI')\n",
    "bulls_rolling_avg = get_rolling_avgs(bulls)\n",
    "enhanced_bulls = enhance_features(bulls_rolling_avg)\n",
    "bulls_next_game = get_next_row(bulls, 1)\n",
    "\n",
    "# Cross validate\n",
    "X = enhanced_bulls.drop(columns=['W/L'])\n",
    "y = enhanced_bulls['W/L']\n",
    "cross_validate_model(X, y)\n",
    "\n",
    "# Get prediction\n",
    "model, y_test, y_pred = calibrated_logistic_regression(enhanced_bulls, bulls_next_game)\n",
    "\n",
    "\n",
    "celts = get_raw_df('BOS')\n",
    "celts_rolling_avg = get_rolling_avgs(celts)\n",
    "enhanced_celts = enhance_features(celts_rolling_avg)\n",
    "celts_next_game = get_next_row(celts, 1)\n",
    "\n",
    "# Cross validate\n",
    "X = enhanced_celts.drop(columns=['W/L'])\n",
    "y = enhanced_celts['W/L']\n",
    "cross_validate_model(X, y)\n",
    "\n",
    "# Get prediction\n",
    "model, y_test, y_pred = calibrated_logistic_regression(enhanced_celts, celts_next_game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_to_head(home_team:str, away_team:str):\n",
    "    home_teamdf = get_raw_df(home_team)\n",
    "    home_rolling_avg = get_rolling_avgs(home_teamdf)\n",
    "    enhanced_home = enhance_features(home_rolling_avg)\n",
    "    home_next_game = get_next_row(home_teamdf, 1)\n",
    "\n",
    "    # Cross validate\n",
    "    X = enhanced_home.drop(columns=['W/L'])\n",
    "    y = enhanced_home['W/L']\n",
    "    cross_validate_model(X, y)\n",
    "\n",
    "    # Get prediction\n",
    "    model, y_test, y_pred = calibrated_logistic_regression(enhanced_home, home_next_game)\n",
    "\n",
    "\n",
    "    away_teamdf = get_raw_df(away_team)\n",
    "    away_rolling_avg = get_rolling_avgs(away_teamdf)\n",
    "    enhanced_away = enhance_features(away_rolling_avg)\n",
    "    away_next_game = get_next_row(away_teamdf, 0)\n",
    "\n",
    "    # Cross validate\n",
    "    X = enhanced_away.drop(columns=['W/L'])\n",
    "    y = enhanced_away['W/L']\n",
    "    cross_validate_model(X, y)\n",
    "\n",
    "    # Get prediction\n",
    "    model, y_test, y_pred = calibrated_logistic_regression(enhanced_away, away_next_game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 0.714, AUC: 0.400\n",
      "Fold 2 - Accuracy: 0.500, AUC: 0.625\n",
      "\n",
      "Average Accuracy: 0.607 (+/- 0.107)\n",
      "Average AUC: 0.512 (+/- 0.112)\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "\n",
      "Predicted Outcome (1=Win, 0=Loss): 1\n",
      "Win Probability: 56.62%\n",
      "Loss Probability: 43.38%\n",
      "Fold 1 - Accuracy: 0.571, AUC: 0.750\n",
      "Fold 2 - Accuracy: 0.500, AUC: 0.222\n",
      "\n",
      "Average Accuracy: 0.536 (+/- 0.036)\n",
      "Average AUC: 0.486 (+/- 0.264)\n",
      "Accuracy: 0.5\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "\n",
      "Predicted Outcome (1=Win, 0=Loss): 1\n",
      "Win Probability: 51.72%\n",
      "Loss Probability: 48.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobdavis/SportsModeling/sportsModeling/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "head_to_head('CHO', 'NYK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏀 **Cross-Validating the Bulls' Road to Victory!** 🏀  \n",
    "\n",
    "We’re stepping up the game with cutting-edge **machine learning techniques** to predict NBA outcomes. This isn’t just sports analytics; it’s a fusion of **data-driven insights** and **court-side strategy**!  \n",
    "\n",
    "By fine-tuning features like **offensive/defensive efficiency**, **momentum**, and **advanced stats**, we’re bringing a new level of precision to basketball predictions. Who needs a crystal ball when you’ve got this level of technical prowess?  \n",
    "\n",
    "Get ready to **train, test, and WIN**—because this is where **science meets sports**. 🏆 Data has never dunked harder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def calibrated_logistic_regression(rolling_avgs, next_game_row):\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    # Prepare data\n",
    "    X = rolling_avgs.drop(columns=['W/L'])\n",
    "    y = rolling_avgs['W/L']\n",
    "    \n",
    "    # Get feature columns to ensure consistency\n",
    "    feature_columns = X.columns\n",
    "    next_game_row = next_game_row[feature_columns]  # Ensure same columns as training data\n",
    "    \n",
    "    # Split data \n",
    "    test_size = int(X.shape[0] * 0.2)\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "    \n",
    "    # Create pipeline with imputer\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', C=1.0, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Calibrated model\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        pipeline, \n",
    "        cv=2,\n",
    "        method='sigmoid'\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = calibrated_model.predict(X_test)\n",
    "    y_pred_proba = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    \n",
    "    # Predict next game\n",
    "    predicted_outcome = calibrated_model.predict(next_game_row)\n",
    "    predicted_proba = calibrated_model.predict_proba(next_game_row)\n",
    "    \n",
    "    print(\"Predicted Outcome (1=Win, 0=Loss):\", predicted_outcome[0])\n",
    "    print(\"Win Probability: {:.2%}\".format(predicted_proba[0][1]))\n",
    "    print(\"Loss Probability: {:.2%}\".format(predicted_proba[0][0]))\n",
    "    \n",
    "    return calibrated_model, y_test, y_pred\n",
    "\n",
    "def get_next_row(raw_data_df, home_away):\n",
    "    # Get and validate stats\n",
    "    number_stats = get_number_stats_categories()\n",
    "    number_stats = [stat for stat in number_stats if stat in raw_data_df.columns]\n",
    "    \n",
    "    # Get last 5 games and ensure numeric\n",
    "    last_5_games = raw_data_df.tail(5).copy()\n",
    "    for stat in number_stats:\n",
    "        last_5_games[stat] = pd.to_numeric(last_5_games[stat], errors='coerce')\n",
    "    \n",
    "    # Calculate averages for next game\n",
    "    next_game_features = {}\n",
    "    for stat in number_stats:\n",
    "        next_game_features[f'Avg_{stat}'] = last_5_games[stat].mean()\n",
    "    \n",
    "    # Add derived features\n",
    "    next_game_features['Off_Eff'] = next_game_features['Avg_ORtg'] * next_game_features['Avg_eFG%']\n",
    "    next_game_features['Def_Eff'] = next_game_features['Avg_DRtg'] * next_game_features['Avg_OppeFG%']\n",
    "    next_game_features['Off_Def_Ratio'] = next_game_features['Avg_ORtg'] / next_game_features['Avg_DRtg']\n",
    "    \n",
    "    # Calculate Win_Streak from last 5 games\n",
    "    next_game_features['Win_Streak'] = (last_5_games['W/L'] == '1').sum()\n",
    "    \n",
    "    # Create single row DataFrame with home/away\n",
    "    next_game_row = pd.DataFrame([next_game_features])\n",
    "    next_game_row.insert(0, 'Home/Away', home_away)\n",
    "    \n",
    "    # Standardize features to match training data\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = next_game_row.select_dtypes(include=['float64']).columns\n",
    "    next_game_row[numeric_features] = scaler.fit_transform(next_game_row[numeric_features])\n",
    "    \n",
    "    return next_game_row\n",
    "\n",
    "def cross_validate_model(X, y, n_splits=2):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    # Create pipeline with imputer\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        y_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        aucs.append(auc)\n",
    "        \n",
    "        # print(f\"Fold {fold} - Accuracy: {acc:.3f}, AUC: {auc:.3f}\")\n",
    "    \n",
    "    print(f\"Average Accuracy: {np.mean(accuracies):.3f} (+/- {np.std(accuracies):.3f})\")\n",
    "    print(f\"Average AUC: {np.mean(aucs):.3f} (+/- {np.std(aucs):.3f})\")\n",
    "\n",
    "\n",
    "def enhance_features(rolling_avgs_df):\n",
    "    # Create interaction features\n",
    "    rolling_avgs_df['Off_Eff'] = rolling_avgs_df['Avg_ORtg'] * rolling_avgs_df['Avg_eFG%']\n",
    "    rolling_avgs_df['Def_Eff'] = rolling_avgs_df['Avg_DRtg'] * rolling_avgs_df['Avg_OppeFG%']\n",
    "    \n",
    "    # Create momentum features (if you have date information)\n",
    "    rolling_avgs_df['Win_Streak'] = (rolling_avgs_df['W/L'] == '1').rolling(5).sum()\n",
    "    \n",
    "    # Create relative metrics\n",
    "    rolling_avgs_df['Off_Def_Ratio'] = rolling_avgs_df['Avg_ORtg'] / rolling_avgs_df['Avg_DRtg']\n",
    "    \n",
    "    # Standardize all numeric features\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = rolling_avgs_df.select_dtypes(include=['float64']).columns\n",
    "    rolling_avgs_df[numeric_features] = scaler.fit_transform(rolling_avgs_df[numeric_features])\n",
    "    \n",
    "    return rolling_avgs_df\n",
    "\n",
    "\n",
    "def head_to_head(home_team:str, away_team:str):\n",
    "    away_teamdf = get_raw_df(away_team)\n",
    "    away_rolling_avg = get_rolling_avgs(away_teamdf)\n",
    "    enhanced_away = enhance_features(away_rolling_avg)\n",
    "    away_next_game = get_next_row(away_teamdf, 0)\n",
    "\n",
    "    # Cross validate\n",
    "    X = enhanced_away.drop(columns=['W/L'])\n",
    "    y = enhanced_away['W/L']\n",
    "    print(away_team)\n",
    "    cross_validate_model(X, y)\n",
    "\n",
    "    # Get prediction\n",
    "    model, y_test, y_pred = calibrated_logistic_regression(enhanced_away, away_next_game)\n",
    "\n",
    "\n",
    "    home_teamdf = get_raw_df(home_team)\n",
    "    home_rolling_avg = get_rolling_avgs(home_teamdf)\n",
    "    enhanced_home = enhance_features(home_rolling_avg)\n",
    "    home_next_game = get_next_row(home_teamdf, 1)\n",
    "\n",
    "    # Cross validate\n",
    "    X = enhanced_home.drop(columns=['W/L'])\n",
    "    y = enhanced_home['W/L']\n",
    "    print('\\n', home_team, sep='')\n",
    "    cross_validate_model(X, y)\n",
    "\n",
    "    # Get prediction\n",
    "    model, y_test, y_pred = calibrated_logistic_regression(enhanced_home, home_next_game)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏀 WE JUST BUILT AN NBA PREDICTION MONSTER!!! 🚀\n",
    "\n",
    "## ACHIEVEMENTS UNLOCKED:\n",
    "- SCRAPED DATA LIKE AN ABSOLUTE MACHINE 🤖\n",
    "- ROLLED THOSE AVERAGES SMOOTHER THAN STEPH'S JUMPER 🎯\n",
    "- ENGINEERED FEATURES SO FIRE THE DATA CAUGHT FLAMES 🔥\n",
    "- PIPELINE CLEANER THAN PRIME MAGIC'S PASSING GAME ⚡\n",
    "\n",
    "## THE ONLY L WE TOOK?\n",
    "Letting scikit-learn handle the logistic regression... \n",
    "BUT THAT'S LIKE SAYING JORDAN DIDN'T BUILD HIS OWN SHOES! 👟\n",
    "\n",
    "# WE REALLY JUST DID THAT! 🏆\n",
    "# FROM SCRATCH! 💪\n",
    "# LIKE A BOSS! 👑\n",
    "\n",
    "### WHAT'S NEXT?\n",
    "TAKING 👏 OVER 👏 THE 👏 WORLD 👏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_enhanced_regression(away_team, home_team):\n",
    "    # Scrape the advanced stats for two NBA teams that are going to play each other next (eg. CHI and BOS)\n",
    "    away = get_raw_df(away_team)\n",
    "    home = get_raw_df(home_team)\n",
    "\n",
    "    # Get the rolling averages and next game stats for each team and 1 if they're home, 0 if away\n",
    "    away_rolling_avg = get_rolling_avgs(away)\n",
    "    away_next_game = get_next_row(away, 0)\n",
    "\n",
    "    home_rolling_avg = get_rolling_avgs(home)\n",
    "    home_next_game = get_next_row(home, 1)\n",
    "\n",
    "    # Standardize the features\n",
    "    get_standrdized_stats(away_rolling_avg)\n",
    "    get_standrdized_stats(home_rolling_avg)\n",
    "\n",
    "    # Run the logistic regression\n",
    "    print(away_team)\n",
    "    m, y, yw = calibrated_logistic_regression(away_rolling_avg, away_next_game)\n",
    "    print('\\n', home_team, sep='')\n",
    "    m, y, z = calibrated_logistic_regression(home_rolling_avg, home_next_game)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Stats\n",
      "DET\n",
      "Average Accuracy: 0.500 (+/- 0.115)\n",
      "Average AUC: 0.512 (+/- 0.012)\n",
      "Predicted Outcome (1=Win, 0=Loss): 0\n",
      "Win Probability: 44.32%\n",
      "Loss Probability: 55.68%\n",
      "\n",
      "DEN\n",
      "Average Accuracy: 0.655 (+/- 0.072)\n",
      "Average AUC: 0.582 (+/- 0.096)\n",
      "Predicted Outcome (1=Win, 0=Loss): 1\n",
      "Win Probability: 57.29%\n",
      "Loss Probability: 42.71%\n",
      "\n",
      "Regular Stats\n",
      "DET\n",
      "Predicted Outcome (1=Win, 0=Loss): 0\n",
      "Win Probability: 42.68%\n",
      "Loss Probability: 57.32%\n",
      "\n",
      "DEN\n",
      "Predicted Outcome (1=Win, 0=Loss): 1\n",
      "Win Probability: 60.23%\n",
      "Loss Probability: 39.77%\n"
     ]
    }
   ],
   "source": [
    "def run_models(away_team:str, home_team:str):\n",
    "    print('Enhanced Stats')\n",
    "    head_to_head(away_team=away_team, home_team=home_team)\n",
    "    print('\\nRegular Stats')\n",
    "    non_enhanced_regression(away_team=away_team, home_team=home_team)\n",
    "\n",
    "run_models(away_team='DET', home_team='DEN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sportsModeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
